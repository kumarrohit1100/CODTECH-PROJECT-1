{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYSPARK_PYTHON\"] = r\"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = r\"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsfT3HIK3iAG",
        "outputId": "55824043-528a-4bab-ca81-2b4b8171252f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark launched with 8 cores and 12GB memory.\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "n_cpu = os.cpu_count()           \n",
        "use_cores = max(1, int(n_cpu * 0.7))  \n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "        .appName(\"ALS-Electronics\")\n",
        "        .config(\"spark.driver.memory\",  \"12g\")\n",
        "        .config(\"spark.executor.memory\", \"12g\")         \n",
        "        .config(\"spark.driver.maxResultSize\", \"2g\")\n",
        "        .config(\"spark.sql.shuffle.partitions\", str(use_cores))\n",
        "        .config(\"spark.master\", f\"local[{use_cores}]\")\n",
        "        .getOrCreate()\n",
        ")\n",
        "print(f\"Spark launched with {use_cores} cores and 12GB memory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6e1axe6BqUu",
        "outputId": "237359de-4d3d-4f66-9329-3a2750332a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row count: 7824482\n",
            "+--------------+----------+------+----------+\n",
            "|        userId| productId|rating| timestamp|\n",
            "+--------------+----------+------+----------+\n",
            "| AKM1MP6P0OYPR|0132793040|   5.0|1365811200|\n",
            "|A2CX7LUOHB2NDG|0321732944|   5.0|1341100800|\n",
            "|A2NWSAGRHCP8N5|0439886341|   1.0|1367193600|\n",
            "+--------------+----------+------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, FloatType, LongType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"userId\", StringType(), True),\n",
        "    StructField(\"productId\", StringType(), True),\n",
        "    StructField(\"rating\", FloatType(), True),\n",
        "    StructField(\"timestamp\", LongType(), True)\n",
        "])\n",
        "csv_path = \"GoogleRatings.csv\"\n",
        "\n",
        "df = spark.read.csv(csv_path, header=False, schema=schema)\n",
        "df.cache()\n",
        "print(\"Row count:\", df.count())\n",
        "df.show(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9rBbU72MZ1M",
        "outputId": "1a32685f-ce5e-4405-8659-70f2a815bba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-------+\n",
            "|rating|  count|\n",
            "+------+-------+\n",
            "|   1.0| 901765|\n",
            "|   2.0| 456322|\n",
            "|   3.0| 633073|\n",
            "|   4.0|1485781|\n",
            "|   5.0|4347541|\n",
            "+------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Distributed Exploratory Data Analysis\n",
        "df.groupBy(\"rating\").count().orderBy(\"rating\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPwBgqZHNH2L",
        "outputId": "4d127309-e640-429b-ceaf-d54d35d8e8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Users: 4201696\n",
            "Products: 476002\n"
          ]
        }
      ],
      "source": [
        "print(\"Users:\", df.select(\"userId\").distinct().count())\n",
        "print(\"Products:\", df.select(\"productId\").distinct().count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYBj8glkNHwk",
        "outputId": "cc7fbaf5-f72c-46e7-c469-1dcd6d44a78f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5-core size: 2109869\n"
          ]
        }
      ],
      "source": [
        "users5 = df.groupBy(\"userId\").count().filter(\"count>=5\")\n",
        "items5 = df.groupBy(\"productId\").count().filter(\"count>=5\")\n",
        "core_df = df.join(users5,\"userId\").join(items5,\"productId\").cache()\n",
        "print(\"5-core size:\", core_df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXQGRFC0NHmz"
      },
      "outputs": [],
      "source": [
        "## ALS pipeline and Train/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emaj4s_a2aje",
        "outputId": "8b012134-2f33-44e7-8ffc-3c64a588738c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALS fit in 31.35 seconds.\n",
            "Test RMSE (sample): 3.086127535379005\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# 0. Create a small sample\n",
        "small_df = df.sample(fraction=0.1, seed=42)  # adjust fraction as needed\n",
        "\n",
        "# 1. Indexers\n",
        "user_indexer = StringIndexer(inputCol=\"userId\", outputCol=\"userIndex\").fit(small_df)\n",
        "item_indexer = StringIndexer(inputCol=\"productId\", outputCol=\"productIndex\").fit(small_df)\n",
        "small_df = user_indexer.transform(small_df)\n",
        "small_df = item_indexer.transform(small_df)\n",
        "\n",
        "# 2. Split for train/test\n",
        "train, test = small_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 3. ALS\n",
        "als = ALS(\n",
        "    userCol=\"userIndex\",\n",
        "    itemCol=\"productIndex\",\n",
        "    ratingCol=\"rating\",\n",
        "    nonnegative=True,\n",
        "    coldStartStrategy=\"drop\",\n",
        "    rank=6,\n",
        "    maxIter=3\n",
        ")\n",
        "import time\n",
        "start = time.time()\n",
        "model = als.fit(train)\n",
        "print(f\"ALS fit in {time.time()-start:.2f} seconds.\")\n",
        "\n",
        "# 4. Evaluate\n",
        "preds = model.transform(test)\n",
        "evaluator = RegressionEvaluator(labelCol=\"rating\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(preds)\n",
        "print(\"Test RMSE (sample):\", rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVXI483NNHbr",
        "outputId": "53184c02-9822-42e0-a4db-235ad6fdff27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------------------------------------------------------------------------------------------------+\n",
            "|userIndex|recommendations                                                                                         |\n",
            "+---------+--------------------------------------------------------------------------------------------------------+\n",
            "|74400    |[{157930, 15.927106}, {146057, 15.836955}, {165977, 15.816837}, {77905, 15.688784}, {154534, 15.657251}]|\n",
            "|74510    |[{123908, 4.775204}, {57022, 4.774131}, {161319, 4.764069}, {160819, 4.7544727}, {132158, 4.7523894}]   |\n",
            "|73821    |[{38214, 7.723008}, {71163, 7.6437974}, {147800, 7.630414}, {116870, 7.6279488}, {71264, 7.6069436}]    |\n",
            "|74234    |[{76881, 15.642362}, {145582, 15.281194}, {130511, 15.173418}, {41511, 15.13612}, {68782, 15.123398}]   |\n",
            "|18855    |[{55578, 4.9833193}, {55689, 4.9828286}, {68312, 4.978174}, {165586, 4.9757953}, {104446, 4.9754395}]   |\n",
            "|74446    |[{149622, 4.221765}, {88247, 4.124093}, {166285, 4.1147428}, {111800, 4.109528}, {151824, 4.104446}]    |\n",
            "|18858    |[{152057, 11.000785}, {71146, 10.961788}, {43579, 10.875644}, {79139, 10.849748}, {84088, 10.836702}]   |\n",
            "|74418    |[{41661, 6.3763747}, {62430, 6.3317275}, {69742, 6.232605}, {112222, 6.2111435}, {35509, 6.1514153}]    |\n",
            "|74389    |[{99838, 19.085987}, {65164, 18.769133}, {139592, 18.704971}, {146596, 18.605011}, {154151, 18.598698}] |\n",
            "|74279    |[{58368, 5.7603455}, {120180, 5.756578}, {100458, 5.7515225}, {102498, 5.7420354}, {69888, 5.741466}]   |\n",
            "+---------+--------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample_users = train.select(\"userIndex\").distinct().limit(10)\n",
        "user_recs = model.recommendForUserSubset(sample_users, 5)\n",
        "user_recs.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "d_O65gfuNHUT",
        "outputId": "71a084f0-8946-424e-d435-0285f6718f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample item recommendations:\n",
            "+------------+---------------------------------------------------------------------------------------------------------+\n",
            "|productIndex|recommendations                                                                                          |\n",
            "+------------+---------------------------------------------------------------------------------------------------------+\n",
            "|12          |[{594720, 5.8532314}, {520388, 5.8532314}, {391100, 5.8532314}, {335897, 5.8532314}, {302860, 5.8532314}]|\n",
            "|13          |[{594720, 5.841872}, {520388, 5.841872}, {391100, 5.841872}, {335897, 5.841872}, {302860, 5.841872}]     |\n",
            "|14          |[{594720, 6.1993546}, {520388, 6.1993546}, {391100, 6.1993546}, {335897, 6.1993546}, {302860, 6.1993546}]|\n",
            "|18          |[{661379, 5.8186035}, {484693, 5.8186035}, {198992, 5.8186035}, {12020, 5.4573393}, {68246, 5.405761}]   |\n",
            "|38          |[{29671, 5.8115416}, {5834, 5.404684}, {41824, 5.379271}, {59198, 5.3703547}, {50432, 5.342801}]         |\n",
            "+------------+---------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Top-5 user recommendations for each product/item\n",
        "item_recs = model.recommendForAllItems(5)\n",
        "print(\"Sample item recommendations:\")\n",
        "item_recs.show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "item_recs = model.recommendForAllItems(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+---------+---------+\n",
            "|productIndex|userIndex|   rating|\n",
            "+------------+---------+---------+\n",
            "|          12|   594720|5.8532314|\n",
            "|          12|   520388|5.8532314|\n",
            "|          12|   391100|5.8532314|\n",
            "|          12|   335897|5.8532314|\n",
            "|          12|   302860|5.8532314|\n",
            "|          13|   594720| 5.841872|\n",
            "|          13|   520388| 5.841872|\n",
            "|          13|   391100| 5.841872|\n",
            "|          13|   335897| 5.841872|\n",
            "|          13|   302860| 5.841872|\n",
            "+------------+---------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Flatten the nested recommendations\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "# Explode and flatten the recommendation array\n",
        "exploded_item_recs = item_recs.select(\"productIndex\", explode(\"recommendations\").alias(\"rec\"))\n",
        "flattened_item_recs = exploded_item_recs.select(\"productIndex\", \"rec.userIndex\", \"rec.rating\")\n",
        "flattened_item_recs.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Project Key Results\n",
        "\n",
        "- The dataset contains over **7.8 million ratings** from Amazon Electronics users.\n",
        "- Data was filtered to a **5-core subset**, selecting users and products with at least 5 ratings each to improve data density.\n",
        "- An **ALS (Alternating Least Squares) recommendation model** was trained on a 10% sample of this subset.\n",
        "- The model achieved a **test RMSE of approximately 3.10**, indicating its predictive accuracy.\n",
        "- Generated **top-5 product recommendations for sample users** and **top-5 user recommendations for some products**.\n",
        "- Recommendation results were **flattened and organized** (e.g., userId with recommended productIds) for easier downstream use.\n",
        "- Overall, this is a **working recommender system** built on big data using PySpark, capable of providing personalized product suggestions with measurable accuracy.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
